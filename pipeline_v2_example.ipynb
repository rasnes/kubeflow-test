{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to run a Kubeflow Pipeline locally.\n",
    "\n",
    "Following the instructions here: https://www.kubeflow.org/docs/components/pipelines/sdk-v2/build-pipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.dsl import (\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    ")\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_merge_csv(url: str, output_csv: str):\n",
    "  with urllib.request.urlopen(url) as res:\n",
    "    tarfile.open(fileobj=res, mode=\"r|gz\").extractall('data')\n",
    "  df = pd.concat(\n",
    "      [pd.read_csv(csv_file, header=None) \n",
    "       for csv_file in glob.glob('data/*.csv')])\n",
    "  df.to_csv(output_csv, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_merge_csv(\n",
    "    url='https://storage.googleapis.com/ml-pipeline-playground/iris-csv-files.tar.gz', \n",
    "    output_csv='merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.3,3.3,6.0,2.5,virginica\n",
      "5.8,2.7,5.1,1.9,virginica\n",
      "7.1,3.0,5.9,2.1,virginica\n",
      "6.3,2.9,5.6,1.8,virginica\n",
      "6.5,3.0,5.8,2.2,virginica\n",
      "7.6,3.0,6.6,2.1,virginica\n",
      "4.9,2.5,4.5,1.7,virginica\n",
      "7.3,2.9,6.3,1.8,virginica\n",
      "6.7,2.5,5.8,1.8,virginica\n",
      "7.2,3.6,6.1,2.5,virginica\n"
     ]
    }
   ],
   "source": [
    "!head merged_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubeflow Pipeline\n",
    "\n",
    "Below we will run the above function for downloading and merging CSVs as a two-step pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=['pandas==1.1.4'],\n",
    "    output_component_file='component.yaml'\n",
    ")\n",
    "def merge_csv(tar_data: Input[Artifact], output_csv: Output[Dataset]):\n",
    "  import glob\n",
    "  import pandas as pd\n",
    "  import tarfile\n",
    "\n",
    "  tarfile.open(name=tar_data.path, mode=\"r|gz\").extractall('data')\n",
    "  df = pd.concat(\n",
    "      [pd.read_csv(csv_file, header=None) \n",
    "       for csv_file in glob.glob('data/*.csv')])\n",
    "  df.to_csv(output_csv.path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_downloader_op = kfp.components.load_component_from_url(\n",
    "    'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/contrib/web/Download/component-sdk-v2.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline and create a task from a component:\n",
    "@dsl.pipeline(\n",
    "    name='my-pipeline',\n",
    "    # You can optionally specify your own pipeline_root\n",
    "    # pipeline_root='gs://my-pipeline-root/example-pipeline',\n",
    ")\n",
    "def my_pipeline(url: str):\n",
    "  web_downloader_task = web_downloader_op(url=url)\n",
    "  merge_csv_task = merge_csv(tar_data=web_downloader_task.outputs['data'])\n",
    "  # The outputs of the merge_csv_task can be referenced using the\n",
    "  # merge_csv_task.outputs dictionary: merge_csv_task.outputs['output_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run your pipeline\n",
    "kfp.compiler.Compiler(mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE).compile(\n",
    "    pipeline_func=my_pipeline,\n",
    "    package_path='pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yey! Managed to run to compiled file `pipeline.yaml` file in the Kubeflow Pipelines Web UI!\n",
    "\n",
    "Testing option 2 as well: run the pipeline using Kubeflow Pipelines SDK client. Which also works as expected - yay!\n",
    "The pipeline submitted from this Notebook appeared in the Web UI, and completed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client() # change arguments accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/9918b3c3-8659-498d-b493-63ed54bb6450\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/d2876641-85a2-44fd-9f47-a5c2edbb89dc\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=d2876641-85a2-44fd-9f47-a5c2edbb89dc)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "    # You can optionally override your pipeline_root when submitting the run too:\n",
    "    # pipeline_root='gs://my-pipeline-root/example-pipeline',\n",
    "    arguments={\n",
    "        'url': 'https://storage.googleapis.com/ml-pipeline-playground/iris-csv-files.tar.gz'\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70ffa8e5d46eb383f67d4bacadd16bd944ecc76246af61b9922fa64c34b86b12"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
